
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/rf.ipynb
from pathlib import Path
import numpy as np
from .chem import *
from fastcore.all import *
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score
from sklearn.metrics import matthews_corrcoef, make_scorer
import optuna
from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval

class ParamOpt():
    def __init__(self,x,y):
        self.x = x
        self.y = y
    def __getitem__(self,i): return x[i],y[i]

    def __len__(self): return len(x),len(y)

@patch
@delegates(ParamOpt)
def build_model_hyperopt(opt:ParamOpt, params, **kwargs):

    sk_cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2)

    loss = cross_val_score(RandomForestClassifier(**params, n_jobs=-1),
                           X=opt.x,
                           y=opt.y,
                           cv = sk_cv,
                           scoring=make_scorer(matthews_corrcoef),
                           n_jobs=-1).mean()

    # since the optimize function looks for the minimum
    return {'loss': -1*loss, 'status': STATUS_OK}



@patch
@delegates(ParamOpt)
def run_optimize_optuna(opt: ParamOpt, trial: optuna.Trial, **kwargs):
    

    params={
        'n_estimators' : trial.suggest_int('n_estimators', 200, 2500),
    'max_depth' : trial.suggest_int("max_depth", 2, 30, log=True),
    'min_samples_leaf' : trial.suggest_int("min_samples_leaf", 2, 15),
    'min_samples_split' : trial.suggest_int("min_samples_split", 2, 15)
           }
    
    sk_cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2)

    loss = cross_val_score(RandomForestClassifier(**params, n_jobs=-1),
                           X=opt.x,
                           y=opt.y,
                           cv = sk_cv,
                           scoring=make_scorer(matthews_corrcoef),
                           n_jobs=-1).mean()
    return loss


@patch
@delegates(ParamOpt)
def run_optimize_hyperopt(opt: ParamOpt, space, evals:int, target_name:str, save_results=True, **kwargs):

    if save_results:
        SAVE_DIR = Path(f'rf/optimization/{target_name}')
        SAVE_DIR.mkdir(exist_ok=True,parents=True)
        print(f'Saving to: {SAVE_DIR}\n')

    trial = Trials()

    best = fmin(opt.build_model_hyperopt, space, algo=tpe.suggest,max_evals=evals,trials=trial,return_argmin=False)
    print(f'Best params : {best}')

    # Save
    np.save(SAVE_DIR/f'opt_params_{target_name}.npy', best)
    return best